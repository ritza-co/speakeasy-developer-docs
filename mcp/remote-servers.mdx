---
title: Deploying remote MCP servers
description: Learn how to deploy and harden remote MCP servers.
---

import { Callout } from "@/mdx/components";

# Deploying remote MCP servers

It is still the early days for Model Context Protocol (MCP), and even though it is already widely implemented, the specification is [changing rapidly](https://modelcontextprotocol.io/development/roadmap). For example, in the [March 2025 update](https://modelcontextprotocol.io/specification/2025-03-26/changelog), a new transport, "[streamable HTTP](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http)" was added to the specification, along with an optional [authorization framework](https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization), based on OAuth 2.1.

Keeping up with these changes kind of feels like treading water, but the water is alphabet soup and someone keeps dumping more letters in.

In this guide, we'll focus on one specific topic: hosting remote MCP servers safely. As part of this, we'll cover the new streamable HTTP transport and the authorization framework.

## Remote MCP transports: how we got here

Most of the early MCP servers began as small programs running on a developer's laptop, connected to MCP clients through local `stdio`. Indeed, as of this writing, the very first example on the MCP website still shows all servers running on "your computer". The specification, however, always included server-sent events (SSE) as a transport mechanism - allowing MCP clients to connect to remote servers via HTTP, and for servers to stream responses back to clients.

Besides the risk of prompt-injection, the HTTP+SSE transport part of the specification seems the most contentious in recent online discourse around MCP. This intensified after the release of the March 2025 update, with many commenters concluding that "streamable HTTP" is essentially HTTP+SSE with more steps, and will one day converge on something akin to WebSockets.

We're not throwing a hat in the ring with this debate today, but we'll say this: The specification in its current state is useful without immediate changes to the transport mechanism.

Relying on SSE and the normal HTTP pipeline avoids the complexities of upgrading connections from HTTP to WebSocket. With the addition of session IDs passed via headers in HTTP+SSE, maintaining stickiness in serverless or proxied servers is trivial.

Waiting for all the details to be ironed out feels like debating tabs vs. spaces at this point.

With that out of the way, let's use the protocol we have, even if not everyone agrees about the current direction.

## Why host MCP servers remotely

Remote MCP servers allow teams to connect to a common server that is always available, avoids server version disparity among team members, and avoid sharing secrets (such as organization level API keys) with users.

If your users are less technical, you can also provide a simple web interface to the server, allowing them to run servers and use tools without the need to know how to use the command line or Docker.

Let's look at the options available for hosting remote MCP servers.

## Choose your hosting model

| Hosting model               | Best for                                                              | Pain points                                                           |
|-----------------------------|-----------------------------------------------------------------------|-----------------------------------------------------------------------|
| **Cloudflare Workers**      | need zero-ops edge scale, instant HTTPS, built-in OAuth               | limited CPU / 50 ms wall-clock per event; can't spawn native binaries |
| **Cloud VM**                | want full OS control, can hand-roll networking, cheap burst workloads | you patch and monitor; long-lived SSE needs extra nginx tuning        |
| **Docker / Kubernetes**     | require strict isolation, multi-instance scaling, CI/CD pipelines     | learning curve; cluster maintenance                                   |
| **On-prem (public-facing)** | must access internal data or comply with corporate firewalls          | outbound-only tunnels, complex identity provider integration          |

The protocol is identical across models: an HTTPS endpoint that accepts JSON-RPC 2.0 over an HTTP POST (optionally upgrading to SSE) and streams the response. Only the infrastructure changes.

## Cloudflare Workers deployment

Cloudflare's blog post [Build and deploy Remote Model Context Protocol (MCP) servers to Cloudflare](https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/) walks through all the tools and steps needed to deploy a remote MCP server to Cloudflare Workers.

Let's summarize the steps here by modifying the [Sentry MCP](https://github.com/getsentry/sentry-mcp) server and deploying it to Cloudflare Workers.

### Requirements

You'll need a [Cloudflare](https://www.cloudflare.com/) account (free is fine), and [Node.js](https://nodejs.org/en/download) with [pnpm](https://pnpm.io/installation) installed locally. Our example uses the Sentry MCP server, so you'll also need a Sentry account.

### Start with a template

If you're building your own server, you can start with one of [Cloudflare's many demos](https://github.com/cloudflare/ai/tree/main/demos). But to get something useful up and running in this guide, we decided to use the [Sentry MCP server](https://github.com/getsentry/sentry-mcp) (itself based on the [mcp-github-oauth](https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-github-oauth) demo) as an example.

Clone the Sentry MCP server:

```bash
git clone https://github.com/getsentry/sentry-mcp
cd sentry-mcp
```

### Install dependencies

Install the dependencies using pnpm:

```bash
pnpm install
```

### Authenticate Wrangler with Cloudflare

Wrangler is Cloudflare's CLI for deploying and managing Workers. We'll use `npx` to run it without installing globally.

Check that you can run `npx wrangler`:

```bash
npx wrangler --version
```

This should print the version of Wrangler. If you get an error, you may need to install Node.js or add it to your PATH.

Next, you'll need to authenticate Wrangler with your Cloudflare account. This is a one-time step:

```bash
npx wrangler login
```

This will open a browser window and ask you to log in to your Cloudflare account. Once logged in, you'll be redirected to a page that says, "You have granted authorization to Wrangler!" - you can close this page.

### Create a Cloudflare KV namespace

The Sentry MCP server uses a Cloudflare KV namespace to store OAuth tokens. You can create a new KV namespace using the Wrangler CLI:

```bash
npx wrangler kv namespace create "OAUTH_KV"
```

This will create a new KV namespace and print the ID. Copy this ID, as you'll need it in the next step.

### Configure the project

Now that you have your KV namespace set up, you can configure the project. The `packages/mcp-cloudflare/wrangler.jsonc` file contains all the configuration for your Cloudflare Worker.

Update the `kv_namespaces` section with the ID of the KV namespace you created earlier:

```jsonc !packages/mcp-cloudflare/wrangler.jsonc focus=39
/**
 * For more details on how to configure Wrangler, refer to:
 * https://developers.cloudflare.com/workers/wrangler/configuration/
 */
{
  "$schema": "node_modules/wrangler/config-schema.json",
  "name": "sentry-mcp",
  "main": "./src/server/index.ts",
  "compatibility_date": "2025-03-21",
  "compatibility_flags": [
    "nodejs_compat",
    "nodejs_compat_populate_process_env"
  ],
  // we ask people to configure environment variables in prod
  "keep_vars": true,
  "migrations": [
    {
      "new_sqlite_classes": ["SentryMCP"],
      "tag": "v1"
    }
  ],
  "assets": {
    "directory": "public",
    "binding": "ASSETS",
    "not_found_handling": "single-page-application"
  },
  "vars": {},
  "durable_objects": {
    "bindings": [
      {
        "class_name": "SentryMCP",
        "name": "MCP_OBJECT"
      }
    ]
  },
  "kv_namespaces": [
    {
      "binding": "OAUTH_KV",
      "id": "8dd5e9bafe1945298e2d5ca3b408a553"
    }
  ],
  "ai": {
    "binding": "AI"
  },
  "observability": {
    "enabled": true,
    "head_sampling_rate": 1
  },
  "tail_consumers": [
    // super noisy - disable until it can be improve
    // { "service": "sentry-mcp-tail" }
  ],
  "dev": {
    "port": 8788
  }
}
```

### Create a Sentry API application

Next, you'll need to create a Sentry API application. This is a one-time step that allows the MCP server to authenticate with Sentry.

1. Log in to your Sentry account.
2. Click on your profile picture in the top-left corner to open the menu.
3. Click on **User settings**.
4. Under **API**, click on **Applications**.
5. Click on **Create New Application**.

Take note of the **Client ID** and **Client Secret**. You'll need these in the next step.

### Configure the environment variables

The Sentry MCP server uses environment variables to configure the OAuth flow. You can set these using Cloudflare Wrangler:

Change to the `packages/mcp-cloudflare` directory, where the `wrangler.jsonc` file is located:

```bash
cd packages/mcp-cloudflare
```

Now, set environment variables on Cloudflare using the following commands:

```bash
# Copy the values from your Sentry API application

npx wrangler secret put SENTRY_CLIENT_ID
# Paste the Client ID from Sentry

npx wrangler secret put SENTRY_CLIENT_SECRET
# Paste the Client Secret from Sentry

# Generate a random string and copy it
# (you can also use a password manager to generate this)
openssl rand -base64 32

npx wrangler secret put COOKIE_SECRET
# Paste the random string you generated
```

When prompted, enter the values you copied from the Sentry API application and the random string you generated. This will store the secrets in your Cloudflare account.

### Build the project

Now that you have everything set up, you can build the project. Run the following command in the `packages/mcp-cloudflare` directory:

```bash
pnpm build
```

### Deploy the server

Now that you have everything set up, you can deploy the server to Cloudflare Workers. Run the following command in the `packages/mcp-cloudflare` directory:

```bash
npx wrangler deploy
```

Cloudflare will build the project and deploy it to your account. This may take a few minutes.
Once the deployment is complete, you should see a message like this:

```text
Uploaded sentry-mcp (12.94 sec)
Deployed sentry-mcp triggers (1.33 sec)
  https://sentry-mcp.<your-cloudflare-hostname>.workers.dev
Current Version ID: <version-id>
```

### Test the server

The Sentry MCP repository includes a documentation page that explains how to use the server. Click the link Cloudflare Workers provides to open the docs page in your browser.

![Screenshot of the Sentry MCP web interface with a dark-themed background. The header displays the Sentry MCP logo, version 0.7.1, and a GitHub button in the top right. The main content introduces Sentry MCP as a Model Context Provider for interacting with the Sentry API. A highlighted quote from David Cramer reads: MCP is pretty sweet. Cloudflares support of MCP is pretty sweet. Sentry is pretty sweet. So we made an MCP for Sentry on top of Cloudflare. Below, a section titled What is a Model Context Provider explains it as a way to plug the Sentry API into an LLM, enabling users to ask questions about their data in context. A simple diagram illustrates the flow between User, MCP, Sentry, and Cursor, with speech bubbles showing how the system helps fix issues. The overall tone is professional and informative, designed to welcome developers and provide clear guidance.](./assets/remote-servers/mcp-server-browser.png)

Now let's test the MCP server. Open a terminal and run the following command:

```bash
pnpx @modelcontextprotocol/inspector@0.11.0
```

This will start the MCP inspector, which allows you to interact with the MCP server in your browser.

![MCP Inspector interface showing a browser-based tool for testing MCP connections. The dark-themed interface displays multiple panels: a left sidebar with connection options showing SSE transport selected and a server URL field, a main content area showing connection status as Pending, and a right panel with request/response details. The inspector appears ready to establish a connection to test a remote MCP server, with status indicators and connection controls prominently displayed.](./assets/remote-servers/mcp-inspector.png)

### Setting the redirect URL in Sentry

Before you can connect the MCP Inspector to the Sentry MCP server, you need to set the redirect URL in Sentry. This is the URL that Sentry will redirect to after the OAuth flow is complete.

1. In a new browser tab, go back to the Sentry API application you created earlier.
2. Click on the application name to open the details.
3. Under **Redirect URIs**, add the OAuth callback URL:

   ```text
   https://sentry-mcp.<your-cloudflare-hostname>.workers.dev/oauth/callback
   ```

There is no save button. Unfocus the field, and Sentry should display a toast message indicating that the redirect URL was updated successfully. You can close this tab.

### Connect the MCP Inspector to the Sentry MCP server

Now that you have the redirect URL set up, you can connect the MCP Inspector to the Sentry MCP server.

In the inspector window:

1. Select the SSE transport.
2. Enter the URL of your MCP server (e.g., `https://sentry-mcp.<your-cloudflare-hostname>.workers.dev/sse`).
3. Click **Connect**.

This will establish a connection to the MCP server, which kicks off the OAuth flow. You should see a message in the inspector window indicating that the MCP Inspector is requesting authorization:

![Sentry MCP OAuth authorization dialog in a browser window. The dialog displays the Sentry MCP logo and title at the top, followed by a box stating MCP Inspector is requesting access. Inside the box, details are shown: Name MCP Inspector, Website https://github.com/modelcontextprotocol/inspector, Redirect URIs http://127.0.0.1:6274/oauth/callback. Below, a message explains that the MCP Client is requesting authorization to Sentry MCP and that approval will redirect to complete authentication. Two buttons are at the bottom: Cancel and Approve, with Approve highlighted in light purple. The environment is a dark-themed browser window with a calm, professional tone.](./assets/remote-servers/mcp-sentry-auth.png)

If you look at the URL in the address bar, you'll notice that the redirect URL is set to your local MCP Inspector URL. This is expected, as the MCP Inspector is running locally and will handle the OAuth client flow. Also of note is that the OAuth page you're looking at is hosted on the Sentry MCP server, not on Sentry itself.

This is because the Sentry MCP server is acting as a proxy for the OAuth flow. The MCP Inspector is requesting authorization to access your Sentry account, and the Sentry MCP server is handling the redirect. The MCP specification recommends this approach, as it allows the MCP server to act as a trusted intermediary between the client and the OAuth provider.

There are, in effect, *two* OAuth flows happening here:

1. The MCP Inspector is requesting authorization to access your Sentry MCP server.
2. The Sentry MCP server is requesting authorization to access your Sentry account on behalf of the MCP Inspector.

Click **Approve**. The MCP Inspector will then redirect to the Sentry OAuth page for your app.

![Sentry OAuth authorization dialog for Useful Goshawk, a Sentry API application, requesting access to a Sentry account linked to ritza@example.com. The dialog lists permissions including reading and writing access to organization details, teams, projects, and events. Two buttons labeled Approve and Deny are at the bottom. The interface has a clean, modern design with a purple sidebar and a light background featuring faint Sentry-themed icons. The overall tone is professional and neutral.](./assets/remote-servers/mcp-sentry-approve.png)

In the screenshot above, Useful Goshawk is the name of the Sentry API application we created earlier. The permissions listed are the scopes that the MCP Inspector is requesting access to. You can review these permissions and decide whether to approve or deny the request.

Click **Approve** to grant the MCP Inspector access to your Sentry account. This will redirect you back to the MCP server, which will redirect you back to the MCP Inspector.

![Screenshot of the MCP Inspector web interface focused on the Tools tab. The main panel displays a list of available tools, including list_organizations and list_teams, with descriptions explaining their functions, such as listing all organizations or teams in Sentry. The right panel shows details for the list_organizations tool and a prominent Run Tool button. The interface uses a clean, modern design with a light background and clear section headers. Text in the image includes: Tools, List Tools, Clear, list_organizations, List all organizations that the user has access to in Sentry. Use this tool when you need to: View all organizations in Sentry, Find an organization's slug to aid other tool requests, list_teams, and Run Tool. The overall tone is professional and informative, designed to help users understand and interact with MCP server tools.](./assets/remote-servers/mcp-sentry-list-tools.png)

Click on **Tools** in the top navigation bar, then on **List Tools**. This will show you a list of available tools on the MCP server. You can click on any tool to see its details and run it.

We clicked on **list_organizations** to see a list of all organizations that the user has access to in Sentry. This is a good way to verify that the OAuth flow is working correctly and that the MCP server can access your Sentry account.

Now click the **Run Tool** button to execute the tool. This will send a request to the MCP server, which will then forward it to Sentry and return the response.

![MCP Inspector web interface showing the Tool Result panel after running the list organizations tool. The right panel displays a white background with a green Success status and a code block containing: Organizations, the organization name, Web URL https://url.sentry.io, Region URL https://us.sentry.io, and guidance that the organization name is used as an identifier and regionUrl should be passed if supported. The interface is clean and modern with a light background, presenting information in a professional and informative manner to help users confirm MCP server access to Sentry organizations.](./assets/remote-servers/mcp-list-organizations.png)

The response shows a list of organizations that you have access to in Sentry. This confirms that the MCP server can access your Sentry account and that the OAuth flow is working correctly.

Now everyone on your team can use the Sentry MCP server with their IDEs, LLMs, or any other MCP client. Of course, if you don't need to change the server code, you could just as well use the [hosted Sentry MCP server](https://mcp.sentry.dev/).

## On-premises deployment with Cloudflare tunnels

The Cloudflare Workers model offers a quick deployment path for remote MCP servers, there are scenarios where you need to run MCP servers within your own infrastructure. This is especially true when your MCP server needs to access internal data that can't be exposed directly to the internet, or when you need more control over the runtime environment.

The [Polar.sh MCP server](https://docs.polar.sh/integrate/mcp) is a great example of a server that you might want to run on-premises. It allows AI assistants to interact with your Polar data, including subscriptions, posts, and other content. You may want to run this server on your own infrastructure for security, compliance, or performance reasons.

In this example, we'll deploy the Polar MCP server on-premises and make it securely accessible from anywhere using a [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/) combined with [Zero Trust access](https://developers.cloudflare.com/cloudflare-one/policies/access/) controls.

### Why Cloudflare Tunnel with Zero Trust?

When hosting an MCP server on-premise, you have several options for making it remotely accessible:

1. Open a port on your firewall (not recommended for security reasons).
2. Set up a VPN (adds client complexity and management overhead).
3. Use a reverse proxy with authentication (requires careful configuration)
4. **Use Cloudflare Tunnel with Zero Trust** (our recommended approach)

Cloudflare Tunnel creates an encrypted tunnel between your local server and Cloudflare's edge, with no inbound ports required. Combined with Cloudflare Zero Trust, you can restrict access to specific authenticated users without exposing your server to the public internet.

### Requirements

You'll need:

- A machine to host the Polar MCP server (Linux recommended).
- [Docker](https://docs.docker.com/get-docker/) installed.
- A [Cloudflare](https://www.cloudflare.com/) account with:
  - A domain added to Cloudflare.
  - Zero Trust enabled (free tier works for basic setups).

### Generate a Polar access token

To allow the on-premise MCP server to authenticate with the Polar API, you need to generate an organization access token from the Polar dashboard. The steps below describe this process, referencing the user interface elements shown in the screenshot that follows.

Log in to your Polar organization on [sandbox.polar.sh](https://sandbox.polar.sh) for testing. For production environments, you would typically use [polar.sh](https://polar.sh).

1. In the left-hand navigation sidebar, click on **Settings**.
2. On the Settings page, locate the **Developers** section. Click the **New Token** button to open the **Create Organization Access Token** dialog.
3. In the **Name** field, enter a descriptive name for your token, such as `polar-mcp`.
4. Select an **Expiration** period for the token from the dropdown menu, for example, `7 days`.
5. Under **Scopes**, ensure all permissions are selected by checking each corresponding box. This grants the MCP server the necessary access to interact with your Polar data.
6. Scroll down and click the **Create** button.
7. Polar will display the generated access token only once upon creation. Copy this token and store it. You will need this value for the `POLAR_ACCESS_TOKEN` environment variable when you configure your Docker container in a later step.

![Screenshot of the Polar web interface showing the Create Organization Access Token dialog. The dialog is titled Create Organization Access Token and contains fields for Name, Expiration, and Scopes. The Name field is filled with polar-mcp. Expiration is set to 7 days. The Scopes section lists multiple permissions, each with a checkbox, including openid, profile, email, user:read, organizations:read, organizations:write, custom_fields:read, custom_fields:write, discounts:read, discounts:write, checkout_links:read, checkout_links:write, checkouts:read, checkouts:write, and products:read. All checkboxes are selected. The wider interface shows a sidebar with navigation options such as Home, Products, Benefits, Customers, Sales, Analytics, Finance, and Settings, with Settings highlighted. The overall tone is neutral and professional, designed to guide users through generating an access token.](./assets/remote-servers/polar-token.png)

### Setting up the Polar MCP server

First, let's get the Polar MCP server running locally.

Create a new directory for your Polar MCP deployment:

```bash
mkdir polar-mcp
cd polar-mcp
```

Create a `docker-compose.yml` file with the following content:

```yaml !docker-compose.yml
services:
  polar-mcp:
    image: node:24
    container_name: polar-mcp
    restart: unless-stopped
    command: >
      npx -y --package @polar-sh/sdk -- mcp start --access-token your_polar_api_key --port 3000 --transport sse
    ports:
      - "127.0.0.1:3000:3000"  # Only bind to localhost
```

Replace `your_polar_api_key` with your actual Polar API key generated in the previous step.

Start the Polar MCP server:

```bash
docker compose up -d
```

Verify that the server is running correctly:

```bash
curl http://localhost:3000/sse
```

If everything is working, you should see a response with a session ID and `/message` endpoint.

```text
event: endpoint
data: /message?sessionId=6f884816-1c0b-4543-8465-025cd55c7227
```

### Set up Cloudflare Zero Trust

Now let's configure Cloudflare Zero Trust to secure access to your MCP server.

1. Log in to your Cloudflare account.
2. Navigate to the **Zero Trust** dashboard.
3. If this is your first time, you'll need to create a Zero Trust organization.
4. In the Zero Trust dashboard, go to **Access** > **Applications**.
5. Click **Add an application**.
6. Select **Self-hosted** as the application type.

7. Configure the application:
   - **Application name**: Polar MCP
   - **Session duration**: Choose how long users stay authenticated (e.g., 24 hours)
   - **Application domain**: Choose **+ Add public hostname** and add a subdomain where your MCP server will be available (e.g., `polar-mcp.yourdomain.com`)
   - Leave other settings at default values for now

8. Create an access policy:
   - Click **Add a policy**
   - **Policy name**: Polar MCP Access
   - **Action**: Allow
   - **Configure rules**: Select who should have access to your MCP server
     - For testing, you can use "Emails" and add your email address
     - For a team, you might use "Emails ending in" with your company domain
   - Click **Save**

9. Click **Next** on the application. You can leave the default selected values for the optional settings.
10. Finish by clicking **Save** to create the application.
11. Make sure that the policy you created is linked to the application's policies on the application's **Policies** tab.

### Install and configure Cloudflare Tunnel

Next, we'll set up a tunnel to securely connect your local MCP server to Cloudflare.

1. In the Cloudflare Zero Trust dashboard, navigate to **Networks** > **Tunnels**.
2. Click **Create a tunnel**.
3. Select **Cloudflared** as the tunnel type.
4. Give your tunnel a name (e.g., `polar-mcp-tunnel`).
5. Click **Save tunnel**.

Select **Docker** as the installation method. Instead of running the command in the terminal, copy only the tunnel token from the command.

Now update your `docker-compose.yml` file to include the Cloudflare Tunnel configuration:

```yaml !docker-compose.yml
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: polar-cloudflared
    restart: unless-stopped
    command: tunnel --no-autoupdate run
    environment:
      - TUNNEL_TOKEN=your_tunnel_token
    ports:
      - "127.0.0.1:3001:3000"
```

Replace `your_tunnel_token` with the token you copied earlier.

Now, your `docker-compose.yml` file should look like this:

```yaml !docker-compose.yml
services:
  polar-mcp:
    image: node:24
    container_name: polar-mcp
    restart: unless-stopped
    command: >
      npx -y --package @polar-sh/sdk -- mcp start --access-token your_access_token --port 3000 --transport sse
    ports:
      - "127.0.0.1:3000:3000"  # Only bind to localhost
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: polar-cloudflared
    restart: unless-stopped
    command: tunnel --no-autoupdate run
    environment:
      - TUNNEL_TOKEN=your_tunnel_token
    ports:
      - "127.0.0.1:3001:3000"
```

Restart the Docker containers:

```bash
docker compose down
docker compose up -d
```

In Cloudflare, your tunnel should now show up as a connector.

Click **Next**.

### Configure the tunnel

On the **Route Traffic** page:

1. **Hostname**: Enter the subdomain you chose earlier (e.g., `polar-mcp.yourdomain.com`).
2. **Service**: Enter the URL of your MCP server (e.g., `http://polar-mcp:3000`).
3. Click **Save tunnel**.

### Test your secure MCP setup

Now it's time to test if everything is working correctly. Open a browser and navigate to:

```
https://polar-mcp.yourdomain.com/sse
```

You should be prompted to authenticate through Cloudflare Access.

![Cloudflare Access login screen with a header showing the Cloudflare Access logo. The main panel displays a form titled "Get a login code emailed to you" with an email input field and a blue "Send me a code" button. Below the form is the hostname "cloudflareaccess.com" and "Polar MCP" text. At the bottom of the screen, there's a "Cloudflare Zero Trust" logo. The interface uses a clean, minimalist design with a light gray background for easy readability.](./assets/remote-servers/cloudflare-access-auth.png)

After logging in, you should see a response similar to the one you got when testing the local server.

### Use Cloudflare Warp to connect to the MCP server

In Cloudflare Zero Trust:

1. Navigate to **Gateway**.
2. Click on **Add a device**.
3. Follow the instructions to install Cloudflare Warp on your machine.

Open the Cloudflare Warp app, and navigate to the **Account** tab.

![Screenshot of Cloudflare WARP preferences window showing the Account tab selected. The interface displays a license key, a section labeled Devices using your license key showing macOS (This device) Mac15,12, and a Login to Cloudflare Zero Trust button at the bottom. The window has standard macOS red, yellow, and gray control buttons in the top-left corner and uses a light-colored interface with clear organization of settings options.](./assets/remote-servers/cloudflare-warp.png)

Click the **Login to Cloudflare Zero Trust** button. This will show a modal with a text field to enter your team name.

Your team name is the customizable portion of your team domain. You can view your team name in Zero Trust under **Settings** > **Custom Pages**.

Enter your team name and click **Continue**. This will open a browser window to authenticate with Cloudflare Zero Trust.

Once authenticated, you should see a message indicating that your device is connected to Cloudflare Zero Trust.

<Callout title="Note" type="info">
If you encounter connection issues, you may need to disable Warp's DNS features. To do so you would navigate to your Cloudflare Zero Trust dashboard **Settings** > **Warp Client** > **Profile settings**. Select **Configure** from the 3-dot menu option for your profile and under **Service mode** select "Secure Web Gateway without DNS Filtering".
</Callout>

Once Warp is connected restart your `polar-mcp` and `cloudflared` Docker containers so that `cloudflared` routes tunnel correctly.

### Add Warp access to the MCP server

1. In the Cloudflare Zero Trust dashboard, navigate to **Settings** > **Warp Client**.
2. Under **Device enrollment permissions**, click **Manage**.
3. Click **Login methods**.
4. Activate **WARP authentication identity**.
5. Activate **Apply to all Access applications**.
6. Click **Save**.

### Test the MCP connection

To test the MCP connection, you can use the MCP Inspector we used earlier:

```bash
pnpx @modelcontextprotocol/inspector@0.11.0
```

In the MCP Inspector:

1. Select the SSE transport.
2. Enter your MCP server URL: `https://polar-mcp.yourdomain.com/sse`
3. Click **Connect**.

You'll be redirected to the Cloudflare Access login page. After authentication, the MCP Inspector should connect to your Polar MCP server securely.

![MCP Inspector interface showing a successful connection to the Polar MCP server. The main panel displays a Connected status with a green indicator. The server URL is shown as https://polar-mcp.redirectmap.com/sse. The right panel shows server metadata including the name Polar MCP, version 0.1.0, and capabilities like tools, resources, prompts, and sampling support. The interface uses a clean dark theme design with organized sections for connection details and server information. The overall appearance conveys a stable, functioning connection ready for interaction with the Polar API.](./assets/remote-servers/polar-mcp-connected.png)

With this in place, you can enroll your team members in Cloudflare Zero Trust and provide them with access to the MCP server. They can use any MCP client to connect to the server, and all traffic will be encrypted and authenticated through Cloudflare.

## Comparing deployment models

| Feature                  | Cloudflare Workers         | On-prem with CF Tunnel       |
|--------------------------|----------------------------|------------------------------|
| **Setup complexity**     | Low                        | Medium                       |
| **Maintenance overhead** | Very low (serverless)      | Medium (server management)   |
| **Access to local data** | Limited                    | Full                         |
| **Customization**        | Limited by Workers runtime | Full OS-level control        |
| **Cost model**           | Pay-per-request            | Fixed infrastructure costs   |
| **Cold start latency**   | Yes, but minimal           | None (always running)        |
| **Resource constraints** | CPU/memory limits          | Based on your hardware       |
| **Authentication**       | OAuth providers            | Cloudflare Access (flexible) |

Both deployment models follow the MCP specification, allowing you to choose the approach that best fits your needs without changing client-side integrations.

## Other deployment models

We experimented with several other deployment models, including:

### AWS Lambda

Similar to Cloudflare Workers, but with more complexity in managing the AWS environment and IAM roles. We used the [Run Model Context Protocol (MCP) servers with AWS Lambda](https://github.com/awslabs/run-model-context-protocol-servers-with-aws-lambda) example as a starting point, but ran into a dead end when it came to the SSE transport.

AWS open sourced a [server adapter](https://github.com/awslabs/run-model-context-protocol-servers-with-aws-lambda/blob/main/src/typescript/src/server-adapter/index.ts) for the MCP servers, which simplifies running stdio MCP servers as Lambda functions. However, the adapter depends on a custom transport that no clients currently support.

They note that with upcoming changes to the MCP specification, this may change. For now, we recommend using Cloudflare Workers or an on-premises deployment.

### Container-based deployment with Docker and Kubernetes

This was our initial approach, but we found it to be more complex than necessary for most use cases. While Docker and Kubernetes provide great flexibility and scalability, they also introduce additional overhead in terms of setup and maintenance.

We recommend using Docker for local development and testing, but for production deployments, Kubernetes is often overkill unless you have a specific need for it.

A Kubernetes deployment may suit your needs if you provide MCP servers as a service to multiple teams or customers. In that case, you can use Kubernetes to manage scaling, resource allocation, and isolation between different MCP servers.

## In summary

When deploying remote MCP servers, start with the server's transport mechanism and hosting requirements. If it needs to be publicly accessible, Cloudflare Workers is a great option. If you need to access internal data or have specific hosting requirements, consider using Cloudflare Tunnel with Zero Trust (or a VPN) to securely expose your server.

Then make sure you understand the security implications of your deployment model. For example, if you're using Cloudflare Workers, ensure that your server is properly configured to handle authentication and authorization. If you're using Cloudflare Tunnel, you have to ensure that your server is properly secured and that only authorized users can access it.

Finally, consider the trade-offs between different deployment models. Cloudflare Workers is a great option for quick deployments with minimal maintenance overhead, while on-premises deployments give you more control over the environment but require more management.

As the Model Context Protocol continues to evolve, these deployment patterns will adapt, but the core principles of secure, accessible MCP servers will remain relevant regardless of the transport mechanisms chosen by the specification.

If you have any questions or feedback about this guide, or would like to share your own experiences with deploying remote MCP servers, [please join us on Slack](https://join.slack.com/t/speakeasy-dev/shared_invite/zt-1cwb3flxz-lS5SyZxAsF_3NOq5xc8Cjw).

To find out how we can help you generate your own MCP servers, [get in touch](https://www.speakeasy.com/contact) on our website.
